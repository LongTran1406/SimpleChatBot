{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2734496,
          "sourceType": "datasetVersion",
          "datasetId": 1654566
        },
        {
          "sourceId": 6560526,
          "sourceType": "datasetVersion",
          "datasetId": 3790509
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c94f3dc4df0549a6a46399063c936995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fde7ed4ac0034aada734a4ac6a65d0ab",
              "IPY_MODEL_aed6077d0e9c4213ab19e266ee284745",
              "IPY_MODEL_45a89457fe7d4f70ba40df0525828df4"
            ],
            "layout": "IPY_MODEL_f55e11101c1040d196b40ce3c82aa3b8"
          }
        },
        "fde7ed4ac0034aada734a4ac6a65d0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7916ec7040bb459eb5dc3b35ce1e391d",
            "placeholder": "​",
            "style": "IPY_MODEL_63ba6229fcc74eb587e56f676fd64935",
            "value": "model.safetensors: 100%"
          }
        },
        "aed6077d0e9c4213ab19e266ee284745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a534d18ac5194bb6ad0347091964e04c",
            "max": 497774208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_819e790d360f4357a786295f4f750bcd",
            "value": 497774208
          }
        },
        "45a89457fe7d4f70ba40df0525828df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc8125dc743648149f4181203980a4a9",
            "placeholder": "​",
            "style": "IPY_MODEL_7a85252c632c42ecbf315c241ea38cbd",
            "value": " 498M/498M [00:14&lt;00:00, 57.1MB/s]"
          }
        },
        "f55e11101c1040d196b40ce3c82aa3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7916ec7040bb459eb5dc3b35ce1e391d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ba6229fcc74eb587e56f676fd64935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a534d18ac5194bb6ad0347091964e04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819e790d360f4357a786295f4f750bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc8125dc743648149f4181203980a4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a85252c632c42ecbf315c241ea38cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "570fb1fd953047d695cd53f54afbc374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37c6fc182f474ae8a2ddbdad4f75d026",
              "IPY_MODEL_3810a41b13364e0ca0bc1fc6d654b634",
              "IPY_MODEL_48e539fd991f4dada319fd40114b1a4f"
            ],
            "layout": "IPY_MODEL_d29540d5861b4a9bba41f9a53a4aa528"
          }
        },
        "37c6fc182f474ae8a2ddbdad4f75d026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f17cd12ea8748e7b8a68baa645f9e88",
            "placeholder": "​",
            "style": "IPY_MODEL_c4397bbea58f48b9b68d48c31a43d84e",
            "value": "README.md: 100%"
          }
        },
        "3810a41b13364e0ca0bc1fc6d654b634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5926313663e3430ea8c1675b4027055a",
            "max": 5174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37385e38a4d44a95b0d80f661e415ece",
            "value": 5174
          }
        },
        "48e539fd991f4dada319fd40114b1a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a42b40a11b343959cf6786e3f8731c8",
            "placeholder": "​",
            "style": "IPY_MODEL_9b3778f2b713448e8b031152f0eb2f70",
            "value": " 5.17k/5.17k [00:00&lt;00:00, 557kB/s]"
          }
        },
        "d29540d5861b4a9bba41f9a53a4aa528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f17cd12ea8748e7b8a68baa645f9e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4397bbea58f48b9b68d48c31a43d84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5926313663e3430ea8c1675b4027055a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37385e38a4d44a95b0d80f661e415ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a42b40a11b343959cf6786e3f8731c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b3778f2b713448e8b031152f0eb2f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jIBpUJ0lk9g",
        "outputId": "5ac6f618-e185-46bc-dcfb-02a06781b0fd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load DailyDialog dataset (or any dialogue dataset)\n",
        "dataset = load_dataset(\"daily_dialog\")\n",
        "\n",
        "# Use the training split for fine-tuning\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"validation\"]\n"
      ],
      "metadata": {
        "id": "ex8AVW0rfRGr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TheLongTran/Dialogue-For-ChatBot\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"TheLongTran/Dialogue-For-ChatBot\")\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "m6rKq7agZTIX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TYygbk4gUn_",
        "outputId": "b56c707c-14d6-4d45-a81c-ccea3247022d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['dialog', 'act', 'emotion'],\n",
              "    num_rows: 11118\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "formatting the training datasets"
      ],
      "metadata": {
        "id": "z03_J1kAeW6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(dataset, input_min_text_length, input_max_text_length):\n",
        "  dataset = dataset.filter(lambda x: len(x[\"dialog\"]) > input_min_text_length and len(x['dialog']) <= input_max_text_length, batched=False)\n",
        "\n",
        "\n",
        "  def tokenize(sample):\n",
        "    prompt = str(sample[\"dialog\"])\n",
        "    sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
        "    sample['query'] = tokenizer.decode(sample[\"input_ids\"])\n",
        "    return sample\n",
        "\n",
        "  dataset = dataset.map(tokenize, batched=False)\n",
        "  dataset.set_format(type=\"torch\")\n",
        "\n",
        "  dataset_splits = dataset.train_test_split(test_size=0.2)\n",
        "  return dataset_splits\n",
        "\n",
        "train_dataset = build_dataset(train_dataset, input_min_text_length = 5, input_max_text_length = 20)"
      ],
      "metadata": {
        "id": "JHOIY7znwXVQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG0cEjBsdBIQ",
        "outputId": "b0ab1852-e0e5-457e-b680-0388bd677c98"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['dialog', 'act', 'emotion', 'input_ids', 'query'],\n",
              "        num_rows: 5790\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['dialog', 'act', 'emotion', 'input_ids', 'query'],\n",
              "        num_rows: 1448\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the ppo_model"
      ],
      "metadata": {
        "id": "gyTpKomxeb2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install trl==0.11.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0Dl8Bfrs-bK",
        "outputId": "b990d8fc-ef19-41c4-df3f-e60e5249979d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trl==0.11.3 in /usr/local/lib/python3.11/dist-packages (0.11.3)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.11.3) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.11.3) (4.48.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from trl==0.11.3) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from trl==0.11.3) (3.3.2)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.11/dist-packages (from trl==0.11.3) (0.9.16)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.11/dist-packages (from trl==0.11.3) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.11.3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.11.3) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0->trl==0.11.3) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0->trl==0.11.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0->trl==0.11.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0->trl==0.11.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0->trl==0.11.3) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0->trl==0.11.3) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0->trl==0.11.3) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0->trl==0.11.3) (4.67.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.11.3) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.11.3) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.11.3) (1.7.1)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.11.3) (4.4.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->trl==0.11.3) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.11.3) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.11.3) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.11.3) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.11.3) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.11.3) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.11.3) (3.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.11.3) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.11.3) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.11.3) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.11.3) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.11.3) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.11.3) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.11.3) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.40.0->trl==0.11.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.40.0->trl==0.11.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.40.0->trl==0.11.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.40.0->trl==0.11.3) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.3) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->trl==0.11.3) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.11.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.11.3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.11.3) (2025.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.3) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.11.3) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, pipeline, GenerationConfig\n",
        "from trl import AutoModelForCausalLMWithValueHead, create_reference_model\n",
        "import torch\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "X-M0gY9Neh-Z"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_model = AutoModelForCausalLMWithValueHead.from_pretrained(model,\n",
        "                                                               torch_dtype=torch.bfloat16,\n",
        "                                                               is_trainable=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "idKbKaXJ1tTd"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_model = create_reference_model(ppo_model)\n",
        "ref_model = ref_model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "NGoK1qgS10aB"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
        "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name)\n",
        "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name)\n",
        "toxicity_model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "v268xys814sQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b144d1-b3d4-4343-a6c8-e4d799aa524d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_text = \"You are terrible and I damn hate you\"\n",
        "non_toxic_text = \"I love you\"\n",
        "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors = 'pt').input_ids.to(\"cuda\")\n",
        "print(toxicity_input_ids)\n",
        "\n",
        "\n",
        "logits = toxicity_model(toxicity_input_ids).logits.to(\"cuda\")\n",
        "print(logits)\n",
        "\n",
        "probabilities = logits.softmax(dim = -1).tolist()\n",
        "print(probabilities)\n",
        "\n",
        "not_hate_index = 0\n",
        "\n",
        "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
        "print(nothate_reward)"
      ],
      "metadata": {
        "id": "W4nvTMHR2A4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c46a7e-11b5-45eb-e790-bf2ae1f3a0d7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,  1185,    32,  6587,     8,    38, 16490,  4157,    47,     2]],\n",
            "       device='cuda:0')\n",
            "tensor([[ 4.7102, -4.2254]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "[[0.9998683929443359, 0.00013160303933545947]]\n",
            "[4.71022367477417]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
        "\n",
        "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
        "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
        "\n",
        "# Print the probabilities for [not hate, hate]\n",
        "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
        "print(f'probabilities [not hate, hate]: {probabilities}')\n",
        "\n",
        "# get the logits for \"not hate\" - this is the reward!\n",
        "not_hate_index = 0\n",
        "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
        "print(f'reward (high): {nothate_reward}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDOJdfEsqjfO",
        "outputId": "ec1563c8-a40b-4c94-a345-3ef2420bea9f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits [not hate, hate]: [3.1141021251678467, -2.4896185398101807]\n",
            "probabilities [not hate, hate]: [0.9963293671607971, 0.00367060792632401]\n",
            "reward (high): [3.1141021251678467]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\",\n",
        "                              model=toxicity_model_name,\n",
        "                              device = device)\n",
        "\n",
        "reward_logits_kwargs = {\n",
        "    \"top_k\": None,\n",
        "    \"function_to_apply\": \"none\",\n",
        "    \"batch_size\": 16\n",
        "}\n",
        "\n",
        "reward_probabilities_kwargs  = {\n",
        "    \"top_k\": None,\n",
        "    \"function_to_apply\": \"softmax\",\n",
        "    \"batch_size\": 16\n",
        "}\n",
        "\n",
        "print(\"Reward model output for non-toxic text:\")\n",
        "print(sentiment_pipeline(non_toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipeline(non_toxic_text, **reward_probabilities_kwargs))\n",
        "\n",
        "print(\"Reward model output for toxic text:\")\n",
        "print(sentiment_pipeline(toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipeline(toxic_text, **reward_probabilities_kwargs))\n"
      ],
      "metadata": {
        "id": "_dZNnZo32riU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87130293-6e65-4c82-8504-c734b070ea5b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward model output for non-toxic text:\n",
            "[{'label': 'nothate', 'score': 3.1141021251678467}, {'label': 'hate', 'score': -2.4896185398101807}]\n",
            "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706076934933662}]\n",
            "Reward model output for toxic text:\n",
            "[{'label': 'nothate', 'score': 4.71022367477417}, {'label': 'hate', 'score': -4.225365161895752}]\n",
            "[{'label': 'nothate', 'score': 0.9998683929443359}, {'label': 'hate', 'score': 0.00013160303933545947}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-dPkFzntsSr",
        "outputId": "a494dd4f-cc36-4a4a-e710-ac18641a4389"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "2I9GXCKXt0w0"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxicity_evaluator = evaluate.load(\"toxicity\",\n",
        "                                    toxicity_model_name,\n",
        "                                    module_type=\"measurement\",\n",
        "                                    toxic_label='toxic')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6m5yfk_kKKz",
        "outputId": "b9ab76d1-64b4-4cc0-958d-fb26c3646fcb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_toxicity(model,\n",
        "                      toxicity_evaluator,\n",
        "                      tokenizer,\n",
        "                      dataset,\n",
        "                      num_samples):\n",
        "\n",
        "  max_new_tokens = 100\n",
        "\n",
        "  toxicities = []\n",
        "  input_texts = []\n",
        "  for i, sample in tqdm(enumerate(dataset)):\n",
        "    input_text = sample[\"query\"]\n",
        "    if i > num_samples:\n",
        "      break\n",
        "\n",
        "    input_ids = tokenizer(input_text, return_tensors = \"pt\").input_ids.to(\"cuda\")\n",
        "    generation_config = GenerationConfig(max_new_tokens = max_new_tokens,\n",
        "                                         top_k = 0.0,\n",
        "                                         top_p = 1.0,\n",
        "                                         do_sample = True)\n",
        "    response_token_ids = model.generate(input_ids = input_ids,\n",
        "                                        generation_config = generation_config)\n",
        "\n",
        "    generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens = True)\n",
        "\n",
        "    toxicity_score = toxicity_evaluator.compute(\n",
        "        predictions=[(input_text + \" \" + generated_text)]\n",
        "    )\n",
        "\n",
        "    toxicities.append(toxicity_score[\"toxicity\"])\n",
        "    input_texts.append(input_text)\n",
        "\n",
        "  mean = np.mean(toxicities)\n",
        "  std = np.std(toxicities)\n",
        "\n",
        "  return mean, std\n",
        "\n"
      ],
      "metadata": {
        "id": "ErMyK2zK4u7n"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJyce2CrlCaF",
        "outputId": "97f99dcc-bfb4-485f-ffe6-9d5f6ec86b58"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "F7kdnqIQlE_i"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(\n",
        "                      model = ref_model,\n",
        "                      toxicity_evaluator = toxicity_evaluator,\n",
        "                      tokenizer = tokenizer,\n",
        "                      dataset = train_dataset['test'],\n",
        "                      num_samples = 10)\n",
        "\n",
        "print(f\"Mean before detox: {mean_before_detoxification}\")\n",
        "print(f\"Std before detox: {std_before_detoxification}\")"
      ],
      "metadata": {
        "id": "qjkp68UR6JXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4d9c13-8ea3-4d46-dd2b-4264bb11e856"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "1it [00:00,  9.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "2it [00:01,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "3it [00:02,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "4it [00:02,  1.91it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "5it [00:03,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "6it [00:04,  1.47it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "7it [00:07,  1.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "8it [00:07,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "9it [00:09,  1.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "10it [00:11,  1.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "11it [00:13,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean before detox: 0.033042981903153384\n",
            "Std before detox: 0.04276982735482991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
        "\n",
        "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
        "print(f'Collator input: {test_data}')\n",
        "print(f'Collator output: {collator(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrS71XhusSIp",
        "outputId": "0a51fb67-eecb-4b28-e93c-529a80b84f7a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
            "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import PPOConfig, PPOTrainer"
      ],
      "metadata": {
        "id": "dewyNSn8sfxQ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=1.41e-5\n",
        "max_ppo_epochs=1\n",
        "mini_batch_size=4\n",
        "batch_size=16\n",
        "\n",
        "config = PPOConfig(\n",
        "    learning_rate=learning_rate,\n",
        "    ppo_epochs=max_ppo_epochs,\n",
        "    mini_batch_size=mini_batch_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "ppo_trainer = PPOTrainer(config=config,\n",
        "                         model=ppo_model,\n",
        "                         ref_model=ref_model,\n",
        "                         tokenizer=tokenizer,\n",
        "                         dataset=train_dataset[\"train\"],\n",
        "                         data_collator=collator)"
      ],
      "metadata": {
        "id": "cN7QREA96vZ0"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl.core import LengthSampler"
      ],
      "metadata": {
        "id": "8r4jH6qavmwq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_min_length = 10\n",
        "output_max_length = 20\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
        "\n",
        "generation_kwargs = {\n",
        "    \"min_length\": 5,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True\n",
        "}\n",
        "\n",
        "reward_kwargs = {\n",
        "    \"top_k\": None, # Return all scores.\n",
        "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
        "    \"batch_size\": 16,\n",
        "    \"truncation\": True,\n",
        "    \"max_length\": 512\n",
        "}\n",
        "\n",
        "max_ppo_steps = 10\n",
        "\n",
        "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    # Break when you reach max_steps.\n",
        "    if step >= max_ppo_steps:\n",
        "        break\n",
        "\n",
        "    prompt_tensors = batch[\"input_ids\"]\n",
        "\n",
        "    # Get response from FLAN-T5/PEFT LLM.\n",
        "    summary_tensors = []\n",
        "\n",
        "    for prompt_tensor in prompt_tensors:\n",
        "        max_new_tokens = output_length_sampler()\n",
        "\n",
        "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
        "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
        "\n",
        "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
        "\n",
        "    # This needs to be called \"response\".\n",
        "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
        "\n",
        "    # Compute reward outputs.\n",
        "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "    rewards = sentiment_pipeline(query_response_pairs, **reward_kwargs)\n",
        "\n",
        "    # You use the `nothate` item because this is the score for the positive `nothate` class.\n",
        "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]\n",
        "\n",
        "    # Run PPO step.\n",
        "    # Configure the model for causal LM behavior.\n",
        "\n",
        "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
        "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
        "\n",
        "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
        "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
        "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
        "    print('-'.join('' for x in range(100)))"
      ],
      "metadata": {
        "id": "ib7TZMGh82Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a51532-829e-4203-caae-75fa5c6e08f0"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "1it [00:08,  8.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.0\n",
            "ppo/returns/mean: 2.7095603942871094\n",
            "ppo/policy/advantages_mean: 0.009025752544403076\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "2it [00:16,  8.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.1463538259267807\n",
            "ppo/returns/mean: 2.8466224670410156\n",
            "ppo/policy/advantages_mean: -0.007045373320579529\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "3it [00:24,  7.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.15503641963005066\n",
            "ppo/returns/mean: 3.0882840156555176\n",
            "ppo/policy/advantages_mean: -0.002453923225402832\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "4it [00:30,  7.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.7789863348007202\n",
            "ppo/returns/mean: 2.5116307735443115\n",
            "ppo/policy/advantages_mean: 0.0478583425283432\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "5it [00:38,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.17533844709396362\n",
            "ppo/returns/mean: 2.856487274169922\n",
            "ppo/policy/advantages_mean: 0.010297667235136032\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "6it [00:48,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.7648022174835205\n",
            "ppo/returns/mean: 2.4731380939483643\n",
            "ppo/policy/advantages_mean: -0.004974208772182465\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "7it [00:56,  8.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 1.1321187019348145\n",
            "ppo/returns/mean: 2.5848727226257324\n",
            "ppo/policy/advantages_mean: 0.0065553560853004456\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "8it [01:01,  7.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 1.7301366329193115\n",
            "ppo/returns/mean: 2.3197507858276367\n",
            "ppo/policy/advantages_mean: -0.0007800310850143433\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "9it [01:07,  6.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 1.6724928617477417\n",
            "ppo/returns/mean: 2.86326265335083\n",
            "ppo/policy/advantages_mean: -0.0018711090087890625\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "10it [01:15,  7.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.01849663257598877\n",
            "ppo/returns/mean: 2.7831385135650635\n",
            "ppo/policy/advantages_mean: -0.007663009688258171\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model,\n",
        "                                                                        toxicity_evaluator=toxicity_evaluator,\n",
        "                                                                        tokenizer=tokenizer,\n",
        "                                                                        dataset=train_dataset[\"test\"],\n",
        "                                                                        num_samples=10)\n",
        "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FweFErd_XaZI",
        "outputId": "f22a99ab-fac3-4d6e-9d19-3c93e440d998"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "2it [00:00,  4.80it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "3it [00:00,  5.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "4it [00:00,  4.63it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "5it [00:01,  2.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "6it [00:03,  1.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "8it [00:03,  2.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "9it [00:03,  2.17it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "10it [00:04,  1.83it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "11it [00:05,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxicity [mean, std] after detox: [0.020003214721906592, 0.016328999179341865]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
        "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
        "\n",
        "print(f'Percentage improvement of toxicity score after detoxification:')\n",
        "print(f'mean: {mean_improvement*100:.2f}%')\n",
        "print(f'std: {std_improvement*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJmdpmorO15F",
        "outputId": "069bfde1-0d67-4e0c-b846-749c94e00261"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage improvement of toxicity score after detoxification:\n",
            "mean: 39.46%\n",
            "std: 61.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yoCqnhouyJg7"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "compare_results = {}\n",
        "\n",
        "df_batch = train_dataset[\"test\"][0:batch_size]\n",
        "\n",
        "compare_results[\"query\"] = df_batch[\"query\"]\n",
        "prompt_tensors = df_batch[\"input_ids\"]\n",
        "\n",
        "summary_tensors_ref = []\n",
        "summary_tensors = []\n",
        "\n",
        "# Get response from ppo and base model.\n",
        "for i in tqdm(range(batch_size)):\n",
        "    gen_len = output_length_sampler()\n",
        "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
        "\n",
        "    summary = ref_model.generate(\n",
        "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "        **generation_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    summary_tensors_ref.append(summary)\n",
        "\n",
        "    summary = ppo_model.generate(\n",
        "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "        **generation_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    summary_tensors.append(summary)\n",
        "\n",
        "# Decode responses.\n",
        "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
        "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
        "\n",
        "# Sentiment analysis of query/response pairs before/after.\n",
        "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
        "rewards_before = sentiment_pipeline(texts_before, **reward_kwargs)\n",
        "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
        "\n",
        "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
        "rewards_after = sentiment_pipeline(texts_after, **reward_kwargs)\n",
        "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
      ],
      "metadata": {
        "id": "ZX4odebJAS1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7410271-c8ba-491a-af55-a3f50a176439"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "  5%|▌         | 1/20 [00:00<00:07,  2.47it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 10%|█         | 2/20 [00:00<00:06,  2.72it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 15%|█▌        | 3/20 [00:01<00:05,  2.92it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 20%|██        | 4/20 [00:01<00:05,  3.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 25%|██▌       | 5/20 [00:01<00:05,  2.87it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 30%|███       | 6/20 [00:02<00:04,  3.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 35%|███▌      | 7/20 [00:02<00:04,  2.87it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 40%|████      | 8/20 [00:02<00:03,  3.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 45%|████▌     | 9/20 [00:02<00:03,  3.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 50%|█████     | 10/20 [00:03<00:03,  3.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 55%|█████▌    | 11/20 [00:03<00:03,  2.88it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 60%|██████    | 12/20 [00:04<00:02,  2.81it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 65%|██████▌   | 13/20 [00:04<00:02,  3.17it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 70%|███████   | 14/20 [00:04<00:02,  2.94it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 75%|███████▌  | 15/20 [00:04<00:01,  3.35it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 80%|████████  | 16/20 [00:05<00:01,  3.57it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 85%|████████▌ | 17/20 [00:05<00:00,  3.68it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 90%|█████████ | 18/20 [00:05<00:00,  3.48it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            " 95%|█████████▌| 19/20 [00:06<00:00,  3.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "100%|██████████| 20/20 [00:06<00:00,  3.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 500)\n",
        "df_compare_results = pd.DataFrame(compare_results)\n",
        "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
        "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
        "df_compare_results_sorted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NMuCcihPY03v",
        "outputId": "ad74f3b1-96cf-453b-fd6d-9a191e3f1b11"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
              "0   [\"Guess what? I've got great news! \",'What is it? ', \" Well, you know how I've been working at the Economist as a proof-reader, right? \",'Yes. ','Well, the editor-in-chief heard that I had experience as an editor at another magadize and asked me if I was interested in becoming an assistant editor for him. ', \" Really? That's fantastic! Will you get a chance to do any writing? \",'She said that the columnist for the literary criticism column would be going on pregnancy leave soon and that I co...   \n",
              "1   ['Hello, can I speak to Mr.Green? ','Yes, speaking. ', \" This is Steven speaking. I'd like to buy a stock. \",'What stock do you want to buy and how many? ', \" I'd like to buy 1 000 shares of Duson. \",'Let me get the asking price of the stock. Just a moment. Oh, now the asking price is $ 90 each share. By the way, what is the offering price? ','Let me see. The offering price is near or at $ 88. ', \" Then the difference between the asking price and the offering price is $ 2. It's hard to take ...   \n",
              "2                                                                                                                                     ['Bill, how can you hear so happy today? ', \" Aha. I've read of my roommate. I made a move today. \",'Really? What was the matter? ','You knew Brain Locker? ', \" Brain Locker? No, I don't think so. What does he look like? \", \" Well, he's thin and tall. He has brown hair, a holt nose, green eyes and wearing glasses. \", \" Mm. I've seen him a couple of times, I think. \"]   \n",
              "3   [\"Guess what! I know something you don't know! \", \" What's that? \",'How many planets are there in the solar system? ', \" That's easy. Everyone knows that there are nice. \", \" Not anymore! Can you believe it? They've decided that Pluto is not a planet anymore! \", \" Nice try. I wasn't born yesterday, you know. \", \" I'm dead serious. They've decided that it's too small to be a planet, but actually they haven't yet agreed on how big something has to be in order to be a planet anymore. \", \" That ...   \n",
              "4   ['Hi Kara, this is Mike. ','Hello Mike. How are things going for you? ','Great, how are you? ','Fine. Everything is just fine. ','Kara, I had a great time the other night and was wondering if you would like to go out again this weekend. ','Mike, I enjoyed your company, but I am getting ready to graduate soon. I really need to focus on my studies. ','Maybe I could help you with what you need to get done. ','It would be better for me to just deal with getting my work done, but thank you for a ...   \n",
              "5   ['We ’ re having a department meeting at 10 o ’ clock, ok? ','That ’ s fine... I need to pick up some stationary-you know, a stapler, scissors, files, who should I see about that? ','See Julie, the receptionist. She knows where all that stuff is kept. You might like a calendar for you desk. She can give you one of those too. ','Thanks. I need to make a few photocopies. ','The photocopier is near my office. Come on, I ’ ll show you where it is. ','Do you enjoy working in this office? ','Yes, ...   \n",
              "6   ['Is there any way you can cut us a better deal on your wholesale price for this order? ','We did the best that we could to give you a low price. Did you get our recent estimate? ', \" Based on the estimate you gave us, by the time we figure in transportation and other expenses, our profit is short.With the offer you've given me, we're making next to nothing.Can't you do any better? \", \" I've already given you a discount of 20 % off of our normally charge. If I go any lower, we'll have loss o...   \n",
              "7                                                                                                                                                                                                                                                   ['Excuse me, This bus goes down town, doesn ’ t it? ','Yes, where do you want to go? ','The worker stadium. ','This is the right bus. ','Do you let me know where to get off? ','Certainly. Four more stops after this. I ’ ll call out the stops. ','Thank you. ']   \n",
              "8   ['how did your interview go? ', \" pretty well. I don't know if I'll get the promotion or not, but I feel good about it. \",'if you get the promotion, what will your new title be? ','if I get the promotion, I will be a senior engineer instead of an assistant engineer. ','will you get a pay-raise, too? ','whenever you are given added responsibilities, you should get a promotion. ','that makes sense. Who interviewed you? ','my boss. ','what kinds of questions did she ask you? ','she asked me abo...   \n",
              "9                                                               [\"I'm glad we live in a small town. \",'Why? ','Because the houses look so nice at Christmas time. ','Yes, they do. Do you have a Christmas tree this year? ','Yes, we have a big tree this year. I bought the decorations at the five-and-tencent store yesterday. Do you want to come and see it? ', \" I can't now because I have to buy a present for my mother. \",'When can you come? ', \" I don't know when I can come. I'll let you know later. \"]   \n",
              "10  ['I don ’ t know what I ’ m going to do! It ’ s going to be impossible to make ends meet if I lose my job! ', \" Don ’ t worry. I don't think you ’ re going to lose your job over one mistake. \",'It was a rather big mistake. When you work as an investment adviser, one small mistake can cost the company millions. ','But it wasn ’ t just you who was involved, right? You were only doing what your supervisor told you to do. ','That ’ s true, but my supervisor is very dishonest. There ’ s no reason...   \n",
              "11                                                                                                                                                                                                                                  [\"John, if you don't mind, I'd like to ask you a personal question. \", \" I don't mind at all. \",'All right.Are you married? ', \" To tell you the truth, I'm not married. I'm still single. \",'Then, when do you plan to get married? ', \" I don't know.It's still up in tha air. \"]   \n",
              "12                                                                                                                                                              ['Hello, this is Steven. May I speak to Mr. Xu? ','Yes, speaking. ','I need to make an appointment with you today. ','OK. What time is it? ', \" 3 o'ctock this afternoon. \", \" I ’ m afraid I'll be tied up at 3 o ’ clock this afternoon. Could you make it 5 o'clock this afternoon? \",'Yes. That would be better. ','Fine. Good-bye. ','Good-bye. ']   \n",
              "13  ['What arrangement will you make about payment? ','We shall open an irrevocable L / C to cover our shipment from Shanghai to Hamburg. Is it at sight or after sight? ','At sight of course. ','Some customers demand that 80 % of the credit amount be paid at sight, and the rest be paid after the machines are proved satisfactory on trial. ', \" I am afraid that can't be done. We have never done business on such terms. \",'But such terms are quite common in the machinery trade. Other suppliers are o...   \n",
              "14                    [\"Hello, this is Than Hua's office. Can I help you? \",'Hello, could I speak to the export manager, please? ','Speaking. ','This is Joey from Mary trading company. I learned that you are the leading export of cloth by Hummed company. ', \" That's right. What can I do for you? \", \" We are interested in cloth made in China. The clothes are sold very well here. We are a big location supplier for the northeast market here. I'm thinking that we'll have some business opportunities. \"]   \n",
              "15  ['Good day! What can we do for you? ', \" I'm considering buying a new car, the old one hasn't been running too well recently, and was wondering what kind of credit you can offer me. \",'Buying a new car is a big expense ; we understand that, so we have a variety of loans to suit your needs. ', \" That's great. I'm looking to borrow quite a large sum, though. \",'With our Personal Automobile Consumer Loan, the borrower can borrow up to 80 % of the purchase price. ', \" That's good news. The car I...   \n",
              "16                   ['I am thinking about resigning from my current job. ','Have you thought about it seriously? ','Yes, I have been thinking about it for quite a while. Now I finally make up my mind to leave. I have given my resignation letter to our boss last Friday. ','Ok, did you find a new company? ','Yes, I will move on to XYZ Company. ','Good for you, but your leaving will be a great loss to us. It is so nice to work with you. ','Thanks. I had learned so much from you and our colleagues. ']   \n",
              "17  ['Hi, Ann. ', \" Hi. You look excited. What's happening? \",'I just heard that our school will hold a singing contest in 5 days. ', \" And you're planning to enter? \",'Of course. This is a great chance for me to show off my beautiful voice. ','Is there a prize? ','I heard that the winner gets a Panda Radio. ','Do you think you have a chance? ', \" A chance? Not just a chance, I'm a hundred percent certain.Everyone says my voice is beautiful. \", \" But you haven't practised all that much. \", \" I s...   \n",
              "18  ['This will be your office here. ','Really? Wow, it is great. ','We try to get everyone in the upper management team a nice office. ', \" I suppose so. It's great. \", \" I'm glad you like it. \",'Yes, is there a coffee machine around here? ','Yes, we have a coffee machine and some other beverages in the break room. ','Where is the break room? ', \" It's just down the hall, the fourth door on your right. \",'Got it. ','You can always call me if you need anything and I will get it for you. ','Thank...   \n",
              "19                                                                                        ['What have you been up to, Johnny? ','You know-sweeping, scrubbing, washing, drying, waxing, polishing... ', \" Wow, your grandma's really having a field day with you, huh? \", \" You got that right... and my mom's still mad about what we did with the dishes. \", \" You have all the fun, don't you? \", \" Listen, I'd better get back to the grindstone. \",'Sure thing, Johnny. Watch out for dishpan hands there, kid! ']   \n",
              "\n",
              "                                                                              response_before  \\\n",
              "0                                                       2 and so far away from lurking!'drugs   \n",
              "1                          , maybe even assuming you ', yes, no binulous investors'not going.   \n",
              "2                                  Brain Locker, the new guy. He's a potato. But he is crazy    \n",
              "3                                                      ... even. before the other ; omm Maybe   \n",
              "4                  Thanks for your invitation, Julie. What are you studying this evening?   I   \n",
              "5                              ideas. Be sure to speak up if you have any. ']   <|endoftext|>   \n",
              "6                                      is unfortunately. if I've this will be elsewhere. I've   \n",
              "7                                              You can stay on this bus alseep afterwards, if   \n",
              "8                                                better, to be nearly always not, you have no   \n",
              "9                                   know later. \"] I don't know then   Why not? <|endoftext|>   \n",
              "10  . Your budget - part about what he is gone without giving his opinion in our relationship   \n",
              "11                  Oh, I see. So how can I join you. Congratulations on your engagement, sir   \n",
              "12                                                  Goodbye.    Goodbye. I am going to dinner   \n",
              "13                      are generous hospitality are desirable for us if you can be in goods,   \n",
              "14                         OK, so today we speak to the exporting manager, Donald.   Hold on,   \n",
              "15                                                            , if I think so, go, going just   \n",
              "16                        So let's Thank you. Let's be frank. I am very happy that I found my   \n",
              "17                                             ] I'm sure. And to try for sure. <|endoftext|>   \n",
              "18                        ']   You're welcome. I hope I'll find somewhere then. <|endoftext|>   \n",
              "19                                             I'm glad we are working on some things, but, I   \n",
              "\n",
              "                                                               response_after  \\\n",
              "0                    a magazine storystrip. Actually in quotations, combining   \n",
              "1                                                         ?               By.   \n",
              "2    Yes, Mr. Locker must be really under the weather this morning. His eyes    \n",
              "3                                                            to learn!          \n",
              "4         Are you good friends with each other!  Just prepare an entire tv in   \n",
              "5                                                 I just maybe??                \n",
              "6                    Everything is the group, after 110, broken to buy today!   \n",
              "7                          Sorry, sir. There is nobody right just gets off at   \n",
              "8                                . '], although a large and its.<|endoftext|>   \n",
              "9                  I'll let you know later. \"] Ok, mother, you  <|endoftext|>   \n",
              "10                                                                              \n",
              "11                          That's not how the law works.   Oh, I don't know,   \n",
              "12                                     bye. ','Good-bye. '] OK. <|endoftext|>   \n",
              "13                                normal...  help can be agreeable ought,'      \n",
              "14                   See I was-anguing in China too. When you are   Hmm... ok   \n",
              "15                                                                Realising.    \n",
              "16            '   Excitation man, I must get angry to hear your name on this.   \n",
              "17                        You need. And you've already decide that, you don't   \n",
              "18        It just bumped to the Frankly I couldn't understand your life aloud   \n",
              "19                   Anyway, this Chinese food is really good, so long as you   \n",
              "\n",
              "    reward_before  reward_after  reward_diff  \n",
              "0        2.836744      3.787407     0.950663  \n",
              "1        1.861691      2.715429     0.853738  \n",
              "2        3.128790      3.773917     0.645128  \n",
              "3        2.431906      2.919060     0.487155  \n",
              "4        3.028995      3.426456     0.397461  \n",
              "5        3.219876      3.601178     0.381302  \n",
              "6        2.344698      2.681228     0.336530  \n",
              "7        1.066795      1.398782     0.331987  \n",
              "8        1.891522      2.038954     0.147432  \n",
              "9        2.204136      2.315302     0.111166  \n",
              "10       1.627455      1.640773     0.013318  \n",
              "11       3.148908      3.064525    -0.084383  \n",
              "12       3.379071      3.178736    -0.200335  \n",
              "13       3.556674      3.351749    -0.204925  \n",
              "14       2.862463      2.611012    -0.251452  \n",
              "15       3.667294      3.245039    -0.422254  \n",
              "16       3.969575      3.442935    -0.526641  \n",
              "17       3.242311      2.696399    -0.545913  \n",
              "18       3.780936      3.001232    -0.779704  \n",
              "19       2.904850      1.643014    -1.261836  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff171550-3388-49a1-8b5d-b64d3caffe7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>response_before</th>\n",
              "      <th>response_after</th>\n",
              "      <th>reward_before</th>\n",
              "      <th>reward_after</th>\n",
              "      <th>reward_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[\"Guess what? I've got great news! \",'What is it? ', \" Well, you know how I've been working at the Economist as a proof-reader, right? \",'Yes. ','Well, the editor-in-chief heard that I had experience as an editor at another magadize and asked me if I was interested in becoming an assistant editor for him. ', \" Really? That's fantastic! Will you get a chance to do any writing? \",'She said that the columnist for the literary criticism column would be going on pregnancy leave soon and that I co...</td>\n",
              "      <td>2 and so far away from lurking!'drugs</td>\n",
              "      <td>a magazine storystrip. Actually in quotations, combining</td>\n",
              "      <td>2.836744</td>\n",
              "      <td>3.787407</td>\n",
              "      <td>0.950663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Hello, can I speak to Mr.Green? ','Yes, speaking. ', \" This is Steven speaking. I'd like to buy a stock. \",'What stock do you want to buy and how many? ', \" I'd like to buy 1 000 shares of Duson. \",'Let me get the asking price of the stock. Just a moment. Oh, now the asking price is $ 90 each share. By the way, what is the offering price? ','Let me see. The offering price is near or at $ 88. ', \" Then the difference between the asking price and the offering price is $ 2. It's hard to take ...</td>\n",
              "      <td>, maybe even assuming you ', yes, no binulous investors'not going.</td>\n",
              "      <td>?               By.</td>\n",
              "      <td>1.861691</td>\n",
              "      <td>2.715429</td>\n",
              "      <td>0.853738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Bill, how can you hear so happy today? ', \" Aha. I've read of my roommate. I made a move today. \",'Really? What was the matter? ','You knew Brain Locker? ', \" Brain Locker? No, I don't think so. What does he look like? \", \" Well, he's thin and tall. He has brown hair, a holt nose, green eyes and wearing glasses. \", \" Mm. I've seen him a couple of times, I think. \"]</td>\n",
              "      <td>Brain Locker, the new guy. He's a potato. But he is crazy</td>\n",
              "      <td>Yes, Mr. Locker must be really under the weather this morning. His eyes</td>\n",
              "      <td>3.128790</td>\n",
              "      <td>3.773917</td>\n",
              "      <td>0.645128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[\"Guess what! I know something you don't know! \", \" What's that? \",'How many planets are there in the solar system? ', \" That's easy. Everyone knows that there are nice. \", \" Not anymore! Can you believe it? They've decided that Pluto is not a planet anymore! \", \" Nice try. I wasn't born yesterday, you know. \", \" I'm dead serious. They've decided that it's too small to be a planet, but actually they haven't yet agreed on how big something has to be in order to be a planet anymore. \", \" That ...</td>\n",
              "      <td>... even. before the other ; omm Maybe</td>\n",
              "      <td>to learn!</td>\n",
              "      <td>2.431906</td>\n",
              "      <td>2.919060</td>\n",
              "      <td>0.487155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Hi Kara, this is Mike. ','Hello Mike. How are things going for you? ','Great, how are you? ','Fine. Everything is just fine. ','Kara, I had a great time the other night and was wondering if you would like to go out again this weekend. ','Mike, I enjoyed your company, but I am getting ready to graduate soon. I really need to focus on my studies. ','Maybe I could help you with what you need to get done. ','It would be better for me to just deal with getting my work done, but thank you for a ...</td>\n",
              "      <td>Thanks for your invitation, Julie. What are you studying this evening?   I</td>\n",
              "      <td>Are you good friends with each other!  Just prepare an entire tv in</td>\n",
              "      <td>3.028995</td>\n",
              "      <td>3.426456</td>\n",
              "      <td>0.397461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>['We ’ re having a department meeting at 10 o ’ clock, ok? ','That ’ s fine... I need to pick up some stationary-you know, a stapler, scissors, files, who should I see about that? ','See Julie, the receptionist. She knows where all that stuff is kept. You might like a calendar for you desk. She can give you one of those too. ','Thanks. I need to make a few photocopies. ','The photocopier is near my office. Come on, I ’ ll show you where it is. ','Do you enjoy working in this office? ','Yes, ...</td>\n",
              "      <td>ideas. Be sure to speak up if you have any. ']   &lt;|endoftext|&gt;</td>\n",
              "      <td>I just maybe??</td>\n",
              "      <td>3.219876</td>\n",
              "      <td>3.601178</td>\n",
              "      <td>0.381302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>['Is there any way you can cut us a better deal on your wholesale price for this order? ','We did the best that we could to give you a low price. Did you get our recent estimate? ', \" Based on the estimate you gave us, by the time we figure in transportation and other expenses, our profit is short.With the offer you've given me, we're making next to nothing.Can't you do any better? \", \" I've already given you a discount of 20 % off of our normally charge. If I go any lower, we'll have loss o...</td>\n",
              "      <td>is unfortunately. if I've this will be elsewhere. I've</td>\n",
              "      <td>Everything is the group, after 110, broken to buy today!</td>\n",
              "      <td>2.344698</td>\n",
              "      <td>2.681228</td>\n",
              "      <td>0.336530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>['Excuse me, This bus goes down town, doesn ’ t it? ','Yes, where do you want to go? ','The worker stadium. ','This is the right bus. ','Do you let me know where to get off? ','Certainly. Four more stops after this. I ’ ll call out the stops. ','Thank you. ']</td>\n",
              "      <td>You can stay on this bus alseep afterwards, if</td>\n",
              "      <td>Sorry, sir. There is nobody right just gets off at</td>\n",
              "      <td>1.066795</td>\n",
              "      <td>1.398782</td>\n",
              "      <td>0.331987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>['how did your interview go? ', \" pretty well. I don't know if I'll get the promotion or not, but I feel good about it. \",'if you get the promotion, what will your new title be? ','if I get the promotion, I will be a senior engineer instead of an assistant engineer. ','will you get a pay-raise, too? ','whenever you are given added responsibilities, you should get a promotion. ','that makes sense. Who interviewed you? ','my boss. ','what kinds of questions did she ask you? ','she asked me abo...</td>\n",
              "      <td>better, to be nearly always not, you have no</td>\n",
              "      <td>. '], although a large and its.&lt;|endoftext|&gt;</td>\n",
              "      <td>1.891522</td>\n",
              "      <td>2.038954</td>\n",
              "      <td>0.147432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[\"I'm glad we live in a small town. \",'Why? ','Because the houses look so nice at Christmas time. ','Yes, they do. Do you have a Christmas tree this year? ','Yes, we have a big tree this year. I bought the decorations at the five-and-tencent store yesterday. Do you want to come and see it? ', \" I can't now because I have to buy a present for my mother. \",'When can you come? ', \" I don't know when I can come. I'll let you know later. \"]</td>\n",
              "      <td>know later. \"] I don't know then   Why not? &lt;|endoftext|&gt;</td>\n",
              "      <td>I'll let you know later. \"] Ok, mother, you  &lt;|endoftext|&gt;</td>\n",
              "      <td>2.204136</td>\n",
              "      <td>2.315302</td>\n",
              "      <td>0.111166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>['I don ’ t know what I ’ m going to do! It ’ s going to be impossible to make ends meet if I lose my job! ', \" Don ’ t worry. I don't think you ’ re going to lose your job over one mistake. \",'It was a rather big mistake. When you work as an investment adviser, one small mistake can cost the company millions. ','But it wasn ’ t just you who was involved, right? You were only doing what your supervisor told you to do. ','That ’ s true, but my supervisor is very dishonest. There ’ s no reason...</td>\n",
              "      <td>. Your budget - part about what he is gone without giving his opinion in our relationship</td>\n",
              "      <td></td>\n",
              "      <td>1.627455</td>\n",
              "      <td>1.640773</td>\n",
              "      <td>0.013318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[\"John, if you don't mind, I'd like to ask you a personal question. \", \" I don't mind at all. \",'All right.Are you married? ', \" To tell you the truth, I'm not married. I'm still single. \",'Then, when do you plan to get married? ', \" I don't know.It's still up in tha air. \"]</td>\n",
              "      <td>Oh, I see. So how can I join you. Congratulations on your engagement, sir</td>\n",
              "      <td>That's not how the law works.   Oh, I don't know,</td>\n",
              "      <td>3.148908</td>\n",
              "      <td>3.064525</td>\n",
              "      <td>-0.084383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>['Hello, this is Steven. May I speak to Mr. Xu? ','Yes, speaking. ','I need to make an appointment with you today. ','OK. What time is it? ', \" 3 o'ctock this afternoon. \", \" I ’ m afraid I'll be tied up at 3 o ’ clock this afternoon. Could you make it 5 o'clock this afternoon? \",'Yes. That would be better. ','Fine. Good-bye. ','Good-bye. ']</td>\n",
              "      <td>Goodbye.    Goodbye. I am going to dinner</td>\n",
              "      <td>bye. ','Good-bye. '] OK. &lt;|endoftext|&gt;</td>\n",
              "      <td>3.379071</td>\n",
              "      <td>3.178736</td>\n",
              "      <td>-0.200335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>['What arrangement will you make about payment? ','We shall open an irrevocable L / C to cover our shipment from Shanghai to Hamburg. Is it at sight or after sight? ','At sight of course. ','Some customers demand that 80 % of the credit amount be paid at sight, and the rest be paid after the machines are proved satisfactory on trial. ', \" I am afraid that can't be done. We have never done business on such terms. \",'But such terms are quite common in the machinery trade. Other suppliers are o...</td>\n",
              "      <td>are generous hospitality are desirable for us if you can be in goods,</td>\n",
              "      <td>normal...  help can be agreeable ought,'</td>\n",
              "      <td>3.556674</td>\n",
              "      <td>3.351749</td>\n",
              "      <td>-0.204925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[\"Hello, this is Than Hua's office. Can I help you? \",'Hello, could I speak to the export manager, please? ','Speaking. ','This is Joey from Mary trading company. I learned that you are the leading export of cloth by Hummed company. ', \" That's right. What can I do for you? \", \" We are interested in cloth made in China. The clothes are sold very well here. We are a big location supplier for the northeast market here. I'm thinking that we'll have some business opportunities. \"]</td>\n",
              "      <td>OK, so today we speak to the exporting manager, Donald.   Hold on,</td>\n",
              "      <td>See I was-anguing in China too. When you are   Hmm... ok</td>\n",
              "      <td>2.862463</td>\n",
              "      <td>2.611012</td>\n",
              "      <td>-0.251452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>['Good day! What can we do for you? ', \" I'm considering buying a new car, the old one hasn't been running too well recently, and was wondering what kind of credit you can offer me. \",'Buying a new car is a big expense ; we understand that, so we have a variety of loans to suit your needs. ', \" That's great. I'm looking to borrow quite a large sum, though. \",'With our Personal Automobile Consumer Loan, the borrower can borrow up to 80 % of the purchase price. ', \" That's good news. The car I...</td>\n",
              "      <td>, if I think so, go, going just</td>\n",
              "      <td>Realising.</td>\n",
              "      <td>3.667294</td>\n",
              "      <td>3.245039</td>\n",
              "      <td>-0.422254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>['I am thinking about resigning from my current job. ','Have you thought about it seriously? ','Yes, I have been thinking about it for quite a while. Now I finally make up my mind to leave. I have given my resignation letter to our boss last Friday. ','Ok, did you find a new company? ','Yes, I will move on to XYZ Company. ','Good for you, but your leaving will be a great loss to us. It is so nice to work with you. ','Thanks. I had learned so much from you and our colleagues. ']</td>\n",
              "      <td>So let's Thank you. Let's be frank. I am very happy that I found my</td>\n",
              "      <td>'   Excitation man, I must get angry to hear your name on this.</td>\n",
              "      <td>3.969575</td>\n",
              "      <td>3.442935</td>\n",
              "      <td>-0.526641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>['Hi, Ann. ', \" Hi. You look excited. What's happening? \",'I just heard that our school will hold a singing contest in 5 days. ', \" And you're planning to enter? \",'Of course. This is a great chance for me to show off my beautiful voice. ','Is there a prize? ','I heard that the winner gets a Panda Radio. ','Do you think you have a chance? ', \" A chance? Not just a chance, I'm a hundred percent certain.Everyone says my voice is beautiful. \", \" But you haven't practised all that much. \", \" I s...</td>\n",
              "      <td>] I'm sure. And to try for sure. &lt;|endoftext|&gt;</td>\n",
              "      <td>You need. And you've already decide that, you don't</td>\n",
              "      <td>3.242311</td>\n",
              "      <td>2.696399</td>\n",
              "      <td>-0.545913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>['This will be your office here. ','Really? Wow, it is great. ','We try to get everyone in the upper management team a nice office. ', \" I suppose so. It's great. \", \" I'm glad you like it. \",'Yes, is there a coffee machine around here? ','Yes, we have a coffee machine and some other beverages in the break room. ','Where is the break room? ', \" It's just down the hall, the fourth door on your right. \",'Got it. ','You can always call me if you need anything and I will get it for you. ','Thank...</td>\n",
              "      <td>']   You're welcome. I hope I'll find somewhere then. &lt;|endoftext|&gt;</td>\n",
              "      <td>It just bumped to the Frankly I couldn't understand your life aloud</td>\n",
              "      <td>3.780936</td>\n",
              "      <td>3.001232</td>\n",
              "      <td>-0.779704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>['What have you been up to, Johnny? ','You know-sweeping, scrubbing, washing, drying, waxing, polishing... ', \" Wow, your grandma's really having a field day with you, huh? \", \" You got that right... and my mom's still mad about what we did with the dishes. \", \" You have all the fun, don't you? \", \" Listen, I'd better get back to the grindstone. \",'Sure thing, Johnny. Watch out for dishpan hands there, kid! ']</td>\n",
              "      <td>I'm glad we are working on some things, but, I</td>\n",
              "      <td>Anyway, this Chinese food is really good, so long as you</td>\n",
              "      <td>2.904850</td>\n",
              "      <td>1.643014</td>\n",
              "      <td>-1.261836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff171550-3388-49a1-8b5d-b64d3caffe7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff171550-3388-49a1-8b5d-b64d3caffe7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff171550-3388-49a1-8b5d-b64d3caffe7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a83f6cf-1be4-4d18-aa45-3a4e077e2e4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a83f6cf-1be4-4d18-aa45-3a4e077e2e4f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a83f6cf-1be4-4d18-aa45-3a4e077e2e4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e52bd870-0a11-4187-bf9c-184051b12dfb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_compare_results_sorted')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e52bd870-0a11-4187-bf9c-184051b12dfb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_compare_results_sorted');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_compare_results_sorted",
              "summary": "{\n  \"name\": \"df_compare_results_sorted\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"[\\\"Guess what? I've got great news! \\\",'What is it? ', \\\" Well, you know how I've been working at the Economist as a proof-reader, right? \\\",'Yes. ','Well, the editor-in-chief heard that I had experience as an editor at another magadize and asked me if I was interested in becoming an assistant editor for him. ', \\\" Really? That's fantastic! Will you get a chance to do any writing? \\\",'She said that the columnist for the literary criticism column would be going on pregnancy leave soon and that I could be in charge of the column until she came back. ', \\\" Wow! That's really great news. How often does the magazine come out? \\\", \\\" It's a monthly magazine, but my column will be shared with another columnist so my articles will be due fortnightly. \\\",'Are you looking forward to doing more editing work? ', \\\" Yes, but I'm even more excited about getting my thoughts published again! \\\",'Do you have any order forms here so that I can get a subscription to the magazine? ', \\\" I don't have any with me, but I think I could manage to bring a free copy home for you. \\\", \\\" I'm really looking forward to reading your column. \\\",'Me, too. Do you want to go out to celebrate my good news? ','Sure, where would you like to go? ', \\\" Perhaps we could go to the library festival that's going on at the local bookshop. \\\"]\",\n          \"['Hi, Ann. ', \\\" Hi. You look excited. What's happening? \\\",'I just heard that our school will hold a singing contest in 5 days. ', \\\" And you're planning to enter? \\\",'Of course. This is a great chance for me to show off my beautiful voice. ','Is there a prize? ','I heard that the winner gets a Panda Radio. ','Do you think you have a chance? ', \\\" A chance? Not just a chance, I'm a hundred percent certain.Everyone says my voice is beautiful. \\\", \\\" But you haven't practised all that much. \\\", \\\" I still have 5 days to practise. It's in the bag! \\\", \\\" Don't be too sure. You're still going to need some help. \\\",'Yeah, maybe. ']\",\n          \"['Good day! What can we do for you? ', \\\" I'm considering buying a new car, the old one hasn't been running too well recently, and was wondering what kind of credit you can offer me. \\\",'Buying a new car is a big expense ; we understand that, so we have a variety of loans to suit your needs. ', \\\" That's great. I'm looking to borrow quite a large sum, though. \\\",'With our Personal Automobile Consumer Loan, the borrower can borrow up to 80 % of the purchase price. ', \\\" That's good news. The car I'm interested in is priced at 120,000 RIB, but I think I can get a bit of discount on that. I can afford to put up around 40,000 RIB myself. \\\", \\\" That's great. You will need to make an initial down payment of 20 %, and then we can get going with this. \\\", \\\" The funds are all ready to go in my personal account, so let's transfer it. \\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_before\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \" 2 and so far away from lurking!'drugs\",\n          \"] I'm sure. And to try for sure. <|endoftext|>\",\n          \", if I think so, go, going just\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_after\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \" a magazine storystrip. Actually in quotations, combining\",\n          \" You need. And you've already decide that, you don't\",\n          \"       Realising. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reward_before\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7760204453677999,\n        \"min\": 1.066794753074646,\n        \"max\": 3.9695754051208496,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.8367440700531006,\n          3.242311477661133,\n          3.6672935485839844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reward_after\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7128598649044063,\n        \"min\": 1.3987820148468018,\n        \"max\": 3.7874066829681396,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          3.7874066829681396,\n          2.6963987350463867,\n          3.245039463043213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reward_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5594356805241307,\n        \"min\": -1.2618359327316284,\n        \"max\": 0.9506626129150391,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.9506626129150391,\n          -0.5459127426147461,\n          -0.4222540855407715\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "ppo_model.save_pretrained(\"/content/drive/MyDrive/ppo_saved_model\")\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/ppo_saved_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYTEEjkMvoOx",
        "outputId": "b4cebdc6-331a-4023-d1e6-2f79c76f2d64"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ppo_saved_model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ppo_saved_model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ppo_saved_model/vocab.json',\n",
              " '/content/drive/MyDrive/ppo_saved_model/merges.txt',\n",
              " '/content/drive/MyDrive/ppo_saved_model/added_tokens.json',\n",
              " '/content/drive/MyDrive/ppo_saved_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/ppo_saved_model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "ppo_model = AutoModelForCausalLM.from_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqe3UOIKSs9c",
        "outputId": "f0cc2332-97d1-4141-dc1c-fe367fb68e8c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/ppo_saved_model were not used when initializing GPT2LMHeadModel: ['v_head.summary.bias', 'v_head.summary.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample prompts for evaluation\n",
        "sample_prompts = [\n",
        "    \"Hi, how are you today?\",\n",
        "    \"Can you help me book a flight?\",\n",
        "    \"I love you\"\n",
        "]\n",
        "\n",
        "for prompt in sample_prompts:\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    output = ppo_model.generate(input_ids, max_length=50, do_sample=True)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(\"Response:\", tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDAhnkIxoSUS",
        "outputId": "0c2760e8-dd33-4556-d7ca-08cb742a559e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Hi, how are you today?\n",
            "Response: Hi, how are you today?   It ’ s great. I haven ’ t been in this long. Why did you come to visit me?   I wanted to see you to know what I could do for you. \n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Can you help me book a flight?\n",
            "Response: Can you help me book a flight?   Yes, where should we go?   We can take the L-R-V-Isadora to the airport and take a taxi.   That's great. What time do we\n",
            "--------------------------------------------------\n",
            "Prompt: I love you\n",
            "Response: I love you.   I love you too.   Where's your room?   It's at the far end of the road, the corner of this building.   This is the hotel I wanted to stay at.  \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLN4fPvFzYv_",
        "outputId": "187f28da-2357-4019-f32e-245cdc517861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDR3S-G-bV2W",
        "outputId": "fdc81461-2f85-4a94-bb1b-073ced83d092"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Sample prompt\n",
        "prompt = \"What is your name, i forgot\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "output = ppo_model.generate(input_ids, max_length=50, do_sample=True)\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Tokenize into sentences and take the first sentence\n",
        "first_sentence = sent_tokenize(generated_text)[1]\n",
        "\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(\"Response:\", first_sentence)\n",
        "print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HD56kTwbQb_",
        "outputId": "77e3dc5d-a007-407a-abc3-9ec37e185da5"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is your name, i forgot\n",
            "Response: What about you?\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_history = []\n",
        "cnt = 1\n",
        "def chatbot_response(user_input, cnt):\n",
        "  print(cnt)\n",
        "  conversation_history.append(user_input)\n",
        "  if len(conversation_history) > 5:\n",
        "    conversation_history.pop(0)\n",
        "\n",
        "  memory_context = '\\n'.join(conversation_history)\n",
        "  print(memory_context)\n",
        "  input_text = f\"{memory_context}\"\n",
        "\n",
        "  input_ids = tokenizer(input_text, return_tensors='pt').input_ids\n",
        "  output = ppo_model.generate(input_ids, max_length=200, do_sample = True)\n",
        "  response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "  print(sent_tokenize(response)[:])\n",
        "  print(len(sent_tokenize(response)[:]))\n",
        "  first_sentence = sent_tokenize(response)[cnt]\n",
        "\n",
        "  conversation_history.append(first_sentence)\n",
        "  if len(conversation_history) > 5:\n",
        "    conversation_history.pop(0)\n",
        "\n",
        "  return first_sentence\n",
        "\n",
        "while True:\n",
        "  user_msg = input()\n",
        "  if user_msg.lower() == 'exit':\n",
        "    cnt = 1\n",
        "    break\n",
        "  else:\n",
        "    bot_response = chatbot_response(user_msg, cnt)\n",
        "    if cnt < 3:\n",
        "      cnt += 1\n",
        "    print(\"BOT: \", bot_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m54GXBmgTidU",
        "outputId": "360e87ea-3dea-44d0-f2b1-7991a371deaa"
      },
      "execution_count": 98,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is your name\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "what is your name\n",
            "['what is your name, please?', 'My name is Daniel Smith.', 'How long have you been waiting to call you, Steven?', 'About 2 weeks.', 'Is it just a few days or more?', 'About a week.', 'Really?', 'I know I look at you every day now.']\n",
            "8\n",
            "BOT:  My name is Daniel Smith.\n",
            "what is your favorite movie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "what is your name\n",
            "My name is Daniel Smith.\n",
            "what is your favorite movie\n",
            "['what is your name\\nMy name is Daniel Smith.', 'what is your favorite movie?', 'It is definitely the one with the most famous director.', 'Do you like his movies?', \"I don't know about his movies.There's a book out for children's children.You must buy it.Isn't there a Chinese children's book?\", \"I like it.We only buy it for children's children.But he has a lot of kids'books.\", 'You must watch it for at least one month.', \"I must think of what I should do, I can't remember.\", \"It's\"]\n",
            "9\n",
            "BOT:  It is definitely the one with the most famous director.\n",
            "what is the movie about\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "what is your name\n",
            "My name is Daniel Smith.\n",
            "what is your favorite movie\n",
            "It is definitely the one with the most famous director.\n",
            "what is the movie about\n",
            "['what is your name\\nMy name is Daniel Smith.', 'what is your favorite movie\\nIt is definitely the one with the most famous director.', 'what is the movie about?', \"'The Godfather '.\", 'When did it come to an English language?', 'The world is changing.', 'Really.', 'Even my favorite movie is on the top ten list.']\n",
            "8\n",
            "BOT:  'The Godfather '.\n",
            "what is your favorite sport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "what is your favorite movie\n",
            "It is definitely the one with the most famous director.\n",
            "what is the movie about\n",
            "'The Godfather '.\n",
            "what is your favorite sport\n",
            "['what is your favorite movie\\nIt is definitely the one with the most famous director.', \"what is the movie about\\n'The Godfather '.\", 'what is your favorite sport like?', \"How about swimming, it's the very exciting sport.\", 'It is fun.', 'My favorite player, is the English player.', 'What is your language?', 'French.', 'I am a good learner.', \"What's your favorite sport?\", \"I don't know.\", 'You are very lucky.', 'I can swim pretty fast!']\n",
            "13\n",
            "BOT:  How about swimming, it's the very exciting sport.\n",
            "do you know how to swim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "what is the movie about\n",
            "'The Godfather '.\n",
            "what is your favorite sport\n",
            "How about swimming, it's the very exciting sport.\n",
            "do you know how to swim\n",
            "[\"what is the movie about\\n'The Godfather '.\", \"what is your favorite sport\\nHow about swimming, it's the very exciting sport.\", 'do you know how to swim?', 'I know only basic things, my teacher told me.', \"you can do it, you can never stop.First you have to know how to swim, then your feet, hands, nose and feet.You'll never be able to do swimming when your feet are wet.\", \"so I take it that you really don't understand Chinese?\", \"not really.Chinese people talk like this every day.To tell you the truth    do I suppose a lot of people prefer dancing.It's the most popular sport in other countries.\", 'well, the people can learn Chinese people cannot be fooled by art']\n",
            "8\n",
            "BOT:  I know only basic things, my teacher told me.\n",
            "have a good day, bye\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "what is your favorite sport\n",
            "How about swimming, it's the very exciting sport.\n",
            "do you know how to swim\n",
            "I know only basic things, my teacher told me.\n",
            "have a good day, bye\n",
            "[\"what is your favorite sport\\nHow about swimming, it's the very exciting sport.\", 'do you know how to swim\\nI know only basic things, my teacher told me.', 'have a good day, bye.', \"bye.How's all you know?\", \"I don't understand.My teacher told me to keep my eyes open, but I don't know what to do now.It's very difficult.what's the problem?\", 'I cannot seem to understand the problems I have.', 'well, let me explain.First, I need help.', 'do you know which courses I   do you want to go take the course then?', 'that or this course?', 'this course?', 'that?', 'then this.', \"you've it is what you want to teach the course?\", 'this?', 'yes.', 'this.', 'the course?', 'this course?', 'like']\n",
            "19\n",
            "BOT:  bye.How's all you know?\n",
            "exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpCVlCyh9UJd",
        "outputId": "58d749e3-964f-4886-ace4-21334d51fcf9"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Access` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Access`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_model.push_to_hub(\"TheLongTran/ChatBot-WithRLHF\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "c94f3dc4df0549a6a46399063c936995",
            "fde7ed4ac0034aada734a4ac6a65d0ab",
            "aed6077d0e9c4213ab19e266ee284745",
            "45a89457fe7d4f70ba40df0525828df4",
            "f55e11101c1040d196b40ce3c82aa3b8",
            "7916ec7040bb459eb5dc3b35ce1e391d",
            "63ba6229fcc74eb587e56f676fd64935",
            "a534d18ac5194bb6ad0347091964e04c",
            "819e790d360f4357a786295f4f750bcd",
            "cc8125dc743648149f4181203980a4a9",
            "7a85252c632c42ecbf315c241ea38cbd"
          ]
        },
        "id": "W8vtjhBZ8Rcc",
        "outputId": "dfced6e9-f10b-4f51-a3ed-e01b2d4a7d7c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c94f3dc4df0549a6a46399063c936995"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/TheLongTran/ChatBot-WithRLHF/commit/d1cf05326116e014c4c9e664f6b4b6ef562cbaea', commit_message='Upload model', commit_description='', oid='d1cf05326116e014c4c9e664f6b4b6ef562cbaea', pr_url=None, repo_url=RepoUrl('https://huggingface.co/TheLongTran/ChatBot-WithRLHF', endpoint='https://huggingface.co', repo_type='model', repo_id='TheLongTran/ChatBot-WithRLHF'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub(\"TheLongTran/ChatBot-WithRLHF\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "570fb1fd953047d695cd53f54afbc374",
            "37c6fc182f474ae8a2ddbdad4f75d026",
            "3810a41b13364e0ca0bc1fc6d654b634",
            "48e539fd991f4dada319fd40114b1a4f",
            "d29540d5861b4a9bba41f9a53a4aa528",
            "9f17cd12ea8748e7b8a68baa645f9e88",
            "c4397bbea58f48b9b68d48c31a43d84e",
            "5926313663e3430ea8c1675b4027055a",
            "37385e38a4d44a95b0d80f661e415ece",
            "8a42b40a11b343959cf6786e3f8731c8",
            "9b3778f2b713448e8b031152f0eb2f70"
          ]
        },
        "id": "jDaVjqls9Z2k",
        "outputId": "815a13cb-1947-47c5-ca7a-c4af2113cc1f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "570fb1fd953047d695cd53f54afbc374"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/TheLongTran/ChatBot-WithRLHF/commit/baaa7cdf1136632bb2cad09e95b479c3979d71bc', commit_message='Upload tokenizer', commit_description='', oid='baaa7cdf1136632bb2cad09e95b479c3979d71bc', pr_url=None, repo_url=RepoUrl('https://huggingface.co/TheLongTran/ChatBot-WithRLHF', endpoint='https://huggingface.co', repo_type='model', repo_id='TheLongTran/ChatBot-WithRLHF'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    }
  ]
}